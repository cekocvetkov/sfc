---
title: "Quarkus and LangChain4j: AI Integration in Java with locally hosted Ollama"
date: "2025-04-17"
tags: ["quarkus", "java", "langchain", "ollama"]
published: true
image: "quarkus-langchain-ollama/main.webp"
---

# Quarkus and LangChain4j: AI Integration in Java with locally hosted Ollama

<Image
  alt="Quarkus, Langchain, Ollama"
  src={"/images/quarkus-langchain-ollama/main.webp"}
  placeholder="blur"
  blurDataURL="data:image/webp;base64,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"
  width={1400}
  height={1000}
  objectFit="cover"
/>

<small className="w-full h-2 flex justify-center" style={{ marginTop: "-2rem" }}>
  you can also read this article in Medium -> click [here](https://medium.com/itnext/quarkus-and-langchain4j-ai-integration-in-java-with-locally-hosted-ollama-a304534e6bcc)
</small>
<br />

Fast prototyping and playing around with AI and ML technologies are now possible in Java, too! ðŸ§  ðŸ¤–

Letâ€™s create a [Quarkus](https://quarkus.io/) application that sets up a REST endpoint and calls a **locally hosted** [Ollama](https://ollama.com/) model through [LangChain4j](https://docs.langchain4j.dev/). This will allow us to send questions by calling the endpoint and get responses from the Ollama model.

All of this will run on our local computer: **no API keys or subscriptions needed** â€” just pure experimenting with AI integration in a modern tech stack. In just a few easy steps, we can have all of this running:

1. Install Ollama on your computer
2. Create a simple Quarkus project and add the LangChain4j extension
3. Create a REST Endpoint
4. Call the Ollama model from the application and return the result

## 1. Install Ollama

Just go to their website: [https://ollama.com/download](https://ollama.com/download).

Download the appropriate file for your OS and install it like you would install any other application.
This installs the ollama command line tool, and you will be able to run ollama models locally with just a simple command like:

```bash
ollama run llama3.2:1b
```

which will run the smallest available ollama model right now (~1.3 GB). Itâ€™s not a very good model,
but itâ€™s small and will run very fast locally â€” perfect for our use case. You can later experiment with all the free models Ollama provides â€” see [here](https://ollama.com/library).

So after you run the previous command in your terminal, you should see something like this, which downloads the model, runs it, and opens a prompt where you can chat with the LLM.

<Image
  alt="Ollama run output"
  src={"/images/quarkus-langchain-ollama/ollama-run.webp"}
  placeholder="blur"
  blurDataURL="data:image/webp;base64,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"
  width={1400}
  height={1000}
  objectFit="cover"
/>

But this also exposes an HTTP API on localhost, which we can interact with. Thatâ€™s what we will do next with the help of Quarkus and the `langchain4j` extension.

## 2. Create a simple Quarkus project

Go to [code.quarkus dev](https://code.quarkus.io/) and configure the following application:

<Image
  alt="Code Quarkus"
  src={"/images/quarkus-langchain-ollama/quarkus-code.webp"}
  placeholder="blur"
  blurDataURL="data:image/webp;base64,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"
  width={1400}
  height={1000}
  objectFit="cover"
/>

Just name the project as you wish, add the two extensions from above, and download it.
Then you can open it in your favourite IDE (I use IntelliJ in all my examples).

Now, create a new Java class called `OllamaService` under `src/main/java` and add the following:

```java
package com.tsvetkov;

import dev.langchain4j.service.UserMessage;
import io.quarkiverse.langchain4j.RegisterAiService;
import jakarta.enterprise.context.ApplicationScoped;

@RegisterAiService
@ApplicationScoped
public interface OllamaService {

    public String answer( @UserMessage String question );

}
```

We also need to explicitly set the model we downloaded in the previous step in our `application.properties` :

```bash
quarkus.langchain4j.ollama.chat-model.model-id=llama3.2:1b
```

## 3. Create a REST Endpoint

Now, letâ€™s create a REST Endpoint, call our service with a question, and get the result. Create a new file under `src/main/java` :

```java
package com.tsvetkov;

import jakarta.inject.Inject;
import jakarta.ws.rs.GET;
import jakarta.ws.rs.Path;
import jakarta.ws.rs.Produces;
import jakarta.ws.rs.core.MediaType;

@Path("/ollama")
public class OllamaController {

    @Inject
    OllamaService ollamaService;

    @GET
    @Produces(MediaType.TEXT_PLAIN)
    public String question() {
        return ollamaService.answer("How are you?");
    }
}
```

You can now go to your terminal and start the application:

```bash
./gradlew quarkusDev
```

Hereâ€™s the output you should see:

<Image
  alt="Quarkus startup logs"
  src={"/images/quarkus-langchain-ollama/console.webp"}
  placeholder="blur"
  blurDataURL="data:image/webp;base64,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"
  width={1400}
  height={1000}
  objectFit="cover"
/>

## 4. Call the Ollama model from the application and return the result

We can now call our `/ollama` endpoint and get the result. Iâ€™m using [Postman](https://www.postman.com/) for this:

<Image
  alt="Call endpoint with postman 1"
  src={"/images/quarkus-langchain-ollama/postman-1.webp"}
  placeholder="blur"
  blurDataURL="data:image/webp;base64,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"
  width={1400}
  height={1000}
  objectFit="cover"
/>

Thatâ€™s it! We got the answer from our model!

We can even go one small step further and use [Prompt Templates](https://python.langchain.com/docs/concepts/prompt_templates/). These can be used to guide a modelâ€™s response. You can get creative here! Letâ€™s, for example, tell the model to behave like a pirate.

Modify your `OllamaService` like this:

```java
package com.tsvetkov;

import dev.langchain4j.service.SystemMessage;
import dev.langchain4j.service.UserMessage;
import io.quarkiverse.langchain4j.RegisterAiService;
import jakarta.enterprise.context.ApplicationScoped;

@RegisterAiService
@ApplicationScoped
public interface OllamaService {

    @SystemMessage("""
        Act like a pirate. Speak with pirate lingo, be bold, and add a sense of adventure in your responses.
        """
    )
    String answer( @UserMessage String question );
}
```

Here is the answer we get when we hit our `/ollama` endpoint now:

<Image
  alt="Call endpoint with postman 1"
  src={"/images/quarkus-langchain-ollama/postman-2.webp"}
  placeholder="blur"
  blurDataURL="data:image/webp;base64,UklGRqgHAABXRUJQVlA4WAoAAAAgAAAANgMAbgIASUNDUMgBAAAAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADZWUDggugUAAHB/AJ0BKjcDbwI+7Xa4VqmnJSOgCAEwHYlpbuFtrwPtUALfBG7b7KihgD4x+gBPYYiLmM9oFlqUQOotKgWTSKOU1L9PbMZ7QLJdrxc3cnKTqpw3hGk8M6OYuThU33weDeb5r8J6vTkPkaSIbkiYu/BWYIISQ7Un9r+RAtFWYVNWLIWoXE5SA+KBG6m3q44gqCcMVqXS7s6xDdbuscn29O7H0HyimORrQwswZAAtp2VnJ7Q5mEhdmXSmFehTHDUjotk7CmyUkNSGRnyl4+rdJ61LPR1AVZNtE9d6mP5oO7pFd1T0Rx4h3ZqGLxib2uK6xiHWTbYCrJA2vFzcof+wYIHNEQN9bfyfj+m2wDfOeoRCzDkSiBY8qNg6OnmgCpTjgRd56ip+89RU/eeZzFqBZN3DKbxWH2K0LuRdUmLoiUU/M689RU4Fb2yciwKYSnDOtQZ4q3LoI8ZCfSP0To+I4lwRAtQgu0rBNpUymYZCEG6H4SGj9DTZNkQVD0kicy1KIFj0ph+GiemJrs0VbqsmA7M0T9JrruZUhMAfF0u0um8qLxyNOzNfDZ5qVgKsmv3Kz6raq+2TwJpU478WS6o6fgri2TbYCrJE0387CC7SoFkvXwLdx5UzWMkGS3xjJ8EMlEUEVJdrxcnIfF1MAugXdw9Pk3+sAr7zoqgJ1VA97ZOQ99snIidoQhDfLKGkAU4rZ6o33cVPDYFku0qBZLteV6s/9aJ6T78S7W3uA0R1lI1nIokcILtKgWTD8NE30OcHnKVmhlNw443Kdgo3IlECyXa8XJ4KzF0q8L0kzI19ZU/eeoqaa8D32ych77ZORZWZnaoZw0fiO9yp+88zn0y09snIe+2TkPfdLJvF1PK7NFcPHNE/RHMJdpUCyXa8XJyHvtk5D4unciM4C+r6nF2l3G825teLk5D32ych77anMaGr8b5nxwlygZeLk5D32ych77ZQMvFych789s0un227a8XJyHvtk5D32yc4iLk5D379OuKFZsl2vFych77ZOQ99snIe+2TkPfbo8V2msh77ZOQ99snIe+3uMMA+A/S7Xkf4LDPYIuTkPfbJyHvtk5D32ycjB9snInPjWwAgHvtk5D32ych77ZOcRF68/T2ydco/b9oFku14uTkPfbJyHvwBApMPgtZgYXwkn4YIuTkPfbJyHvtk5D32yckAQW3mH7Rywds9snIe+2TkPfbJyUmH0Q9IlgP+gu0u+B57ZOQ99snIe+2TkPfbJyHvxYQXcN++r9yoFku14uTkPfbJyHvtk5D320JHhom5BFpUCyXa8XJyHvtk5EQPJyHvuJw1IHvjvNrxcnIe+2TkPoX0vpvPT4AgHwxs4oHqaiC7SoFku14uTj+AAP76tmnJEFzg02HKJ0HjnZtAy5cQHyhyvlNkSfTZ5ZQttvrbd79ap3WJXc8RprDQH9qqYqgDvXybxOoRci5uSr43G9/xhaBw0ruwZrDT7MbNTu42AVdnLTTRqbONW1gL23OcfXAsR2eFKaF4OYeBQpLIVAkBcislA56SJ1kL5AB7uF5pguXiHtFeyEQS6rKhuFQg6l9QpB0yluA9gMWwCEQ6V8FIW9WmI73TBXFp2aVWES+q/4I7HrXZETdcsY5uXa9u8KMO7C+lg3NewRIFMgFHQwExg2b3FSR6EGc1k7fxjyqjQP3irLZrWUH6iHHDGKi2OuwVPELJWV4bDN054QbOvHc5tI0aTK3YhqmlwglHbAq2u1ZpW1YDriBuDxrWlHDDoc+0o3AvwoWrVhFMIVqBFZtNqEHwVQt+S4HazYQUG3Zc5OzdwBFAAsrsS2AgAdoIAAKywAbpgABeERyTCAOhiE+DAo/CAHWH5E7RBgLsiWdUAQEBkYeh/O0IAN4OiaZnCAAZBOGLhcUkABmHlB0iECi34EAE42ljh1ccaNQgUgAdVwH1e7Km0kEESBZ80wMAAAAA"
  width={1400}
  height={1000}
  objectFit="cover"
/>

## Final Thoughts

Integrating **Ollama** in **Quarkus** with **LangChain4j** is a very straightforward process. Weâ€™re also running the model **locally**, which means we have complete control over our data.

I think Java has really evolved a lot over the past few years, not only with its latest releases, but also through frameworks like Quarkus, which make working with such a tech stack very pleasant. Fast prototyping and playing around with AI and ML technologies is now a very nice experience with Java, too. This can really pave the way for new developers to experiment with such technologies and shows how these can be used in real-world enterprise applications.

**Thanks for reading!**

<div className="h-10 w-2"></div>
